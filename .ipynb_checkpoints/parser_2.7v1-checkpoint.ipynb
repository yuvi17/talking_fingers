{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.parse.stanford import StanfordParser\n",
    "from nltk.tree import ParentedTree, Tree\n",
    "from nltk import pos_tag,word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    " \n",
    "os.environ['STANFORD_PARSER'] = '/usr/local/Cellar/stanford-parser/3.8.0/libexec'\n",
    "os.environ['STANFORD_MODELS'] = '/usr/local/Cellar/stanford-parser/3.8.0/libexec'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parser = StanfordParser()\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_subject(t):\n",
    "  for s in t.subtrees(lambda t: t.label() == 'NP'):\n",
    "    for n in s.subtrees(lambda n: n.label().startswith('NN')):\n",
    "      if(n != None):\n",
    "          return (n[0], find_attrs(n))\n",
    "    for n in s.subtrees(lambda n: n.label().startswith('PRP')):\n",
    "      if(n != None):\n",
    "          return (n[0], find_attrs(n))\n",
    "    \n",
    "def findQuestionMatter(t):\n",
    "    ans = []\n",
    "    for s in t.subtrees(lambda t: t.label().startswith(\"WH\")):\n",
    "      for n in s.subtrees(lambda n: n.label().startswith('WHADJP')):\n",
    "        for n in s.subtrees((lambda n: n.label() == ('JJ'))):\n",
    "          ans.append(n[0],find_attrs(n))\n",
    "      for n in s.subtrees((lambda n: n.label().startswith('NN'))):\n",
    "        if((n[0],find_attrs(n)) not in ans):\n",
    "            ans.append(n[0])\n",
    "      for n in s.subtrees(lambda n: n.label().startswith('WH')):\n",
    "        for n in s.subtrees((lambda n: n.label() == ('WRB'))):\n",
    "          ans.append(n[0],)\n",
    "        for n in s.subtrees((lambda n: n.label().startswith('WP'))):\n",
    "          ans.append(n[0],'')\n",
    "    return ans\n",
    " \n",
    "# Depth First Search the tree and take the last verb in VP subtree.\n",
    "def find_predicate(t):\n",
    "  v = None\n",
    " \n",
    "  for s in t.subtrees(lambda t: t.label() == 'VP'):\n",
    "    for n in s.subtrees(lambda n: n.label().startswith('VB')):\n",
    "      v = n\n",
    "  if(v != None):\n",
    "      return (v[0], find_attrs(v))\n",
    " \n",
    "# Breadth First Search the siblings of VP subtree\n",
    "# and take the first noun or adjective\n",
    "def find_object(t):\n",
    "  for s in t.subtrees(lambda t: t.label() == 'VP'):\n",
    "    for n in s.subtrees(lambda n: n.label() in ['NP', 'PP', 'ADJP']):\n",
    "      if n.label() in ['NP', 'PP']:\n",
    "        for c in n.subtrees(lambda c: c.label().startswith('NN')):\n",
    "          return (c[0], find_attrs(c))\n",
    "      else:\n",
    "        for c in n.subtrees(lambda c: c.label().startswith('JJ')):\n",
    "          return (c[0], find_attrs(c))\n",
    " \n",
    "def find_attrs(node):\n",
    "  attrs = []\n",
    "  p = node.parent()\n",
    " \n",
    "  # Search siblings of adjective for adverbs\n",
    "  if node.label().startswith('JJ'):\n",
    "    for s in p:\n",
    "      if s.label() == 'RB':\n",
    "        attrs.append(s[0])\n",
    " \n",
    "  elif node.label().startswith('NN'):\n",
    "    for s in p:\n",
    "      if s.label() in ['DT','PRP$','POS','JJ','CD','ADJP','QP','NP']:\n",
    "        attrs.append(s[0])\n",
    "\n",
    "  elif node.label().startswith('NP'):\n",
    "    for s in p:\n",
    "      if s.label() in ['PRP$','NN']:\n",
    "        attrs.append(s[0])\n",
    " \n",
    "  # Search siblings of verbs for adverb phrase\n",
    "  elif node.label().startswith('VB'):\n",
    "    for s in p:\n",
    "      if s.label() == 'ADVP':\n",
    "        attrs.append(' '.join(s.flatten()))\n",
    " \n",
    "  # Search uncles\n",
    "  # if the node is noun or adjective search for prepositional phrase\n",
    "  if node.label().startswith('JJ') or node.label().startswith('NN'):\n",
    "      for s in p.parent():\n",
    "        if s != p and s.label() == 'PP':\n",
    "          attrs.append(' '.join(s.flatten()))\n",
    " \n",
    "  elif node.label().startswith('VB'):\n",
    "    for s in p.parent():\n",
    "      if s != p and s.label().startswith('VB'):\n",
    "        attrs.append(' '.join(s.flatten()))\n",
    " \n",
    "  return attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parseSentence(sentence):\n",
    "    import re\n",
    "    stopwords = [\"are\",\"is\",\"am\",\"was\",\"were\",\"a\",\"an\",\"the\",\"do\",\"did\"]\n",
    "    \n",
    "    replace = {\n",
    "        'many' : 'number',\n",
    "        'I' : 'me',\n",
    "        'my' : 'me'\n",
    "    }\n",
    "    \n",
    "    stopwords = set(stopwords)\n",
    "    res = list(parser.raw_parse(sentence))[0]\n",
    "    print(res)\n",
    "    res = ParentedTree.convert(res)\n",
    "    res.pretty_print()\n",
    "    subjects = find_subject(res)\n",
    "    if(subjects == None):\n",
    "        subjects = (\"\",[])\n",
    "    objects = find_object(res)\n",
    "    if(objects == None):\n",
    "        objects = (\"\",[])\n",
    "    verbs = find_predicate(res)\n",
    "    if(verbs == None):\n",
    "        verbs = (\"\",[])\n",
    "    attributes = find_attrs(res)\n",
    "    if(attributes == None):\n",
    "        attributes = (\"\",[])\n",
    "    ques = findQuestionMatter(res)\n",
    "    if(ques == None):\n",
    "        ques = (\"\",[])\n",
    "    print(subjects)\n",
    "    print(objects)\n",
    "    print(verbs)\n",
    "    print(attributes)\n",
    "    print(ques)\n",
    "    print(pos_tag(word_tokenize(sentence)))\n",
    "    \n",
    "    sent = \"\"\n",
    "    for s in subjects[1]:\n",
    "        if(s not in stopwords):\n",
    "            sent = sent + \" \" + s + \" \"\n",
    "    if(subjects[0] not in sent):\n",
    "        sent = sent + \" \" + subjects[0] + \" \"\n",
    "    for o in objects[1]:\n",
    "        if(o not in stopwords and o not in sent):\n",
    "            sent = sent + \" \" + o + \" \"\n",
    "    if(objects[0] not in sent and objects[0] not in stopwords):\n",
    "        sent = sent + \" \" + ps.stem(objects[0]) + \" \"\n",
    "    \n",
    "    for v in verbs[1]:\n",
    "        if(v not in stopwords):\n",
    "            sent = sent + \" \" + ps.stem(v) + \" \"\n",
    "    if(verbs[0] not in sent and ps.stem(verbs[0]) not in stopwords):\n",
    "        sent = sent + \" \" + ps.stem(verbs[0]) + \" \"\n",
    "    for q in ques:\n",
    "        if(q[0] not in stopwords and q[0] not in set(sent)):\n",
    "            sent = sent + \" \" + q[0] + \" \"\n",
    "    return re.sub( '\\s+', ' ', sent ).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('/Users/yjaiswal/Development/eng2isl/vocab/Absent.mp4')\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret is True:\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    cv2.imshow('frame',gray)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
